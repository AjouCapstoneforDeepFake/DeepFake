# -*- coding: utf-8 -*-
"""pretrained EfficientNet-V2 Training code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u2gy_leAkRJg7-EM1aBRKDq8GCCK2UPc
"""

# 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

import torch

# CUDA가 사용 가능한지 확인
print(torch.cuda.is_available())  # True면 GPU가 사용 가능, False면 사용 불가

# CUDA의 cuDNN 버전 확인
print(torch.backends.cudnn.version())

# PyTorch 버전 확인
print(torch.__version__)

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models
import torch.nn as nn
import torch.optim as optim
from torch.utils.data.dataset import random_split
from PIL import Image
import os
import cv2
from torchvision import datasets
import glob

from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights
from PIL import Image

# Custom Dataset 정의
class CustomDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = os.listdir(root_dir)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.images[idx])
        image = Image.open(img_name)
        if self.transform:
            image = self.transform(image)
        return image


# 전처리 설정 및 정규화 진행
transform_train = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

transform_val = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# ImageFolder 데이터셋 로드 및 train, val 정의
train_dataset = datasets.ImageFolder(root= '#학습데이터셋 경로', transform=transform_train)
idx_to_cls = {v: k for k, v in train_dataset.class_to_idx.items()}
print(train_dataset.class_to_idx)  # {'fake': 0, 'real': 1}

val_dataset = datasets.ImageFolder(root='#검증데이터셋 경로', transform=transform_val) #test dataset을 validation set으로 설정하고 성능 추이 확인

# DataLoader 설정
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# EfficientNetV2 모델 불러오기 (ImageNet 사전 학습된 가중치 사용)
weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1
model = efficientnet_v2_s(weights=weights)

# 마지막 분류기를 이진 분류에 맞게 수정 (EfficientNet-v2 용)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)

# 장치 설정
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)


# 클래스 수 확인
class_folder_dir = glob.glob('#학습데이터셋 경로')
num_classes = len(class_folder_dir)
print(f"Number of classes: {num_classes}")

import matplotlib.pyplot as plt
from PIL import ImageFile
import torch.nn.functional as F
from torch.optim import AdamW


# 모델 학습 및 검증 함수
def train_and_validate_model(train_loader, val_loader, model, criterion, optimizer, scheduler, num_epochs=25, dropout_rate=0.5):
    best_acc = 0.0
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []

    def apply_dropout(x):
        return F.dropout(x, p=dropout_rate, training=True)

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        running_corrects = 0

        for i, (inputs, labels) in enumerate(train_loader):
            if i % 10 == 0:
                print(f"Processing batch {i}/{len(train_loader)} in epoch {epoch+1}/{num_epochs}")
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            outputs = apply_dropout(outputs)

            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)

        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc.item())

        model.eval()
        val_loss = 0.0
        val_corrects = 0
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            with torch.no_grad():
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1)
                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss = val_loss / len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)

        val_losses.append(val_loss)
        val_accuracies.append(val_acc.item())

        print(f'Epoch {epoch+1}/{num_epochs}, '
              f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, '
              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')

        scheduler.step()

        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), '/content/drive/MyDrive/model_path.pth')

    return model, train_losses, train_accuracies, val_losses, val_accuracies

# 손실 함수 및 옵티마이저, 스케줄러 설정
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=0.05, weight_decay=0.005)  #Learning rate와 L2 정규화 weight_decay 설정


# 학습 실행
model, train_losses, train_accuracies, val_losses, val_accuracies = train_and_validate_model(
    train_loader, val_loader, model, criterion, optimizer, scheduler, num_epochs=.20, dropout_rate=0.75  #Epoch와 Dropout rate 설정
)

# training and val accuracy와 loss 시각화 / 그래프 그리기
epochs = range(1, len(train_losses) + 1)

plt.figure(figsize=(14, 5))

# Loss 그래프
plt.subplot(1, 2, 1)
plt.plot(epochs, train_losses, label='Training Loss')
plt.plot(epochs, val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

# Accuracy 그래프
plt.subplot(1, 2, 2)
plt.plot(epochs, train_accuracies, label='Training Accuracy')
plt.plot(epochs, val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()
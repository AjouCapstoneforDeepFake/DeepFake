# -*- coding: utf-8 -*-
"""Final Deepfake Image detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18iq_Zkj70qxSrLVyN_YDUMDvn4PjEBX4
"""

# 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

!pip install opencv-python mtcnn
!pip install facenet-pytorch

import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from torchvision import models
import torch.nn as nn
import torch.optim as optim
from torch.utils.data.dataset import random_split
from torch.utils.data import random_split
from PIL import Image
import os
import cv2
from torchvision import datasets
import glob
import random
import time  
from google.colab.patches import cv2_imshow
import numpy as np
from facenet_pytorch import MTCNN

idx_to_cls = {0: 'FAKE', 1: 'REAL'}


# GPU 설정
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
mtcnn = MTCNN(keep_all=True, device=device)  # 얼굴 탐지기 초기화

# 모델 로드 함수
def load_model(model_path, num_classes):
    model = models.efficientnet_v2_s(pretrained=False)
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    model.load_state_dict(torch.load(model_path))
    model.to(device)
    model.eval()
    return model

# 얼굴 인식 및 크롭 함수
def detect_and_crop_face(image_path):
    img = Image.open(image_path).convert("RGB")  # 이미지를 RGB로 변환
    faces = mtcnn(img)  # 얼굴 탐지 및 추출

    if faces is not None:
        if faces.ndim == 4:  
            face = faces[0]
        else:  
            face = faces

        # 224x224로 리사이즈 및 정규화
        transform = transforms.Compose([
            transforms.Resize((224, 224)),  # PIL 이미지 크기 조정
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # 텐서를 PIL 이미지로 변환
        face_np = face.permute(1, 2, 0).cpu().numpy()  # 텐서를 numpy 배열로 변환 (HWC 형식)
        face_pil = Image.fromarray((face_np * 255).astype(np.uint8))  # PIL 이미지로 변환
        face_tensor = transform(face_pil).unsqueeze(0)  # 배치 차원 추가 및 정규화
        return face_tensor, face_pil
    else:
        print("얼굴을 찾지 못했습니다.")
        return None, None


def predict_image(image_path, model):
    face_tensor, face_pil = detect_and_crop_face(image_path)  # 얼굴 탐지 및 크롭
    if face_tensor is None:
        return

    face_tensor = face_tensor.to(device)  # GPU로 이동
    with torch.no_grad():
        outputs = model(face_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        max_prob, predicted = torch.max(probabilities, 1)

    predicted_label = idx_to_cls[predicted.item()]
    print(f"Predicted class -> predict_label: {predicted_label}")
    return face_pil  # PIL 이미지 반환

# 모델 및 테스트 이미지 경로 설정
model = load_model('#최고 정확도 모델 가중치 pth 경로', num_classes=2)
test_image_path = '#탐지할 이미지 경로' 
# 예측 수행 및 얼굴 이미지 반환
cropped_face = predict_image(test_image_path, model)

# 원본 이미지 출력 (크기 조정)
test_img = cv2.imread(test_image_path)
test_img_resized = cv2.resize(test_img, (400, 400))  
cv2_imshow(test_img_resized)

